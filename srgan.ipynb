{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block for iperator\n",
    "def residual_block(ip):\n",
    "    residual_model = tf.keras.layers.Conv2D(64, (3,3), padding='same')(ip)\n",
    "    residual_model = tf.keras.layers.BatchNormalization(momentum= 0.5)(residual_model)\n",
    "    residual_model = tf.keras.layers.PReLU(shared_axes=[1,2])(residual_model)\n",
    "    residual_model = tf.keras.layers.Conv2D(64, (3,3), padding='same')(residual_model)\n",
    "    residual_model = tf.keras.layers.BatchNormalization(momentum= 0.5)(residual_model)\n",
    "    \n",
    "    return tf.keras.layers.Add([ip, residual_model])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_shuffler_block(ip):\n",
    "    ps_model = tf.keras.layers.Conv2d(256, (3,3), padding='same')(ip)\n",
    "    ps_model = tf.keras.layers.Upsampling2D(size = 2)(ps_model)\n",
    "    ps_model = tf.keras.layers.PReLU(shared_axes=[1,2])(ps_model)\n",
    "    \n",
    "    return ps_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(generator, no_res_blocks = 16, no_pixel_shuffler_blocks = 2):\n",
    "    model = tf.keras.layers.Conv2D(64, (9,9), padding='same')(generator)\n",
    "    model = tf.keras.layers.PReLU(shared_axes=[1,2])(model)\n",
    "    \n",
    "    temp = model\n",
    "    \n",
    "    for i in range(no_res_blocks):\n",
    "        model = residual_block(model)\n",
    "    \n",
    "    model = tf.keras.layers.Conv2D(64, (3,3), padding='same')(model)\n",
    "    model = tf.keras.layers.BatchNormalization(momentum= 0.5)(model)\n",
    "    model = tf.keras.layers.Add([model, temp])\n",
    "    \n",
    "    for i in range(no_pixel_shuffler_blocks):\n",
    "        model = pixel_shuffler_block(model)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(3, (9,9), padding='same')(model)\n",
    "\n",
    "    return tf.keras.Model(inputs= generator, outputs= output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_disriminator(discriminator):\n",
    "    filters = [128, 256, 512]\n",
    "    strides = [1, 2]\n",
    "    model = tf.keras.layers.Conv2D(64, (3,3), strides= 1, padding='same')(discriminator)\n",
    "    model = tf.keras.layers.LeakyReLU(alpha=0.2)(model)\n",
    "    \n",
    "    model = tf.keras.layers.Conv2D(64, (3,3), strides= 2, padding='same')(model)\n",
    "    model = tf.keras.layers.BatchNormalization(momentum = 0.8)(model)\n",
    "    model = tf.keras.layers.LeakyReLU(alpha=0.2)(model)\n",
    "    \n",
    "    for filter in filters:\n",
    "        for stride in strides:       \n",
    "            model = tf.keras.layers.Conv2D(filter, (3,3), strides= stride, padding='same')(model)\n",
    "            model = tf.keras.layers.BatchNormalization(momentum = 0.8)(model)\n",
    "            model = tf.keras.layers.LeakyReLU(alpha=0.2)(model)\n",
    "    \n",
    "    model = tf.kera.layers.Flatten()(model)\n",
    "    model = tf.keras.layers.Dense(1024)(model)\n",
    "    model = tf.keras.layers.LeakyReLU(alpha= 0.2)(model)\n",
    "    model = tf.keras.layers.Dense(1, activation='sigmoid')(model)\n",
    "    \n",
    "    return tf.keras.Model(inputs= discriminator, outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg(hr_shape):\n",
    "    vgg = VGG19(weights='imagenet', include_top=False, input_shape=hr_shape)\n",
    "    \n",
    "    return tf.keras.Model(inputs= vgg.inputs, output= vgg.layers[10].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(generator, discriminator, vgg, lr_ip, hr_ip):\n",
    "    gen_img = generator(lr_ip)\n",
    "    \n",
    "    gen_features = vgg(gen_img)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    disc_result = discriminator(gen_img)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[lr_ip, hr_ip], outputs= [disc_result, gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 # total number of images used for training\n",
    "lr_path = \"data/lr_images\"\n",
    "hr_path = \"data/hr_images\"\n",
    "lr_list = os.listdir(lr_path)[:n]\n",
    "\n",
    "lr_images = []\n",
    "for lr in lr_list:\n",
    "    img = cv2.imread(lr_path + lr)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    lr_images.append(img)\n",
    "\n",
    "hr_list = os.listdir(hr_path)[:n]\n",
    "\n",
    "hr_images = []\n",
    "for hr in hr_list:\n",
    "    img = cv2.imread(lr_path + hr)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    hr_images.append(img)\n",
    "\n",
    "lr_images = np.array(lr_images)\n",
    "hr_images = np.array(hr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying random images\n",
    "test_img_no = random.randint(0, n-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(lr_images[test_img_no]), [32, 32, 3])\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(hr_images[test_img_no]), [128, 128, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the image arrays for training \n",
    "lr_images /= 255\n",
    "hr_images /= 255\n",
    "\n",
    "#train and test split\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, test_size= 0.2, random_state = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the size of splits\n",
    "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
    "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the discriminator, generator and vgg models\n",
    "lr_ip =  tf.keras.layers.Input(shape = lr_shape)\n",
    "hr_ip = tf.keras.layers.Input(shape= hr_shape)\n",
    "\n",
    "generator = create_generator(lr_ip, no_res_blocks=16, no_pixel_shuffler_blocks=2)\n",
    "generator.summary()\n",
    "\n",
    "discriminator = create_disriminator(hr_ip)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer= 'adam', metrics = ['accuracy'])\n",
    "discriminator.summary()\n",
    "\n",
    "vgg = create_vgg((128, 128, 3))\n",
    "vgg.summary()\n",
    "vgg.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the models to a GAN\n",
    "\n",
    "gan_model = final_model(generator, discriminator, vgg, lr_ip, hr_ip)\n",
    "gan_model.compile(loss= ['binary_crossentropy', 'mse'], loss_weghts= [1e-3, 1], optimizer= 'adam')\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_lr_batches = []\n",
    "train_hr_batches = []\n",
    "for i in range (int(hr_train.shape[0])/batch_size):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    train_hr_batches(hr_train[start_index:end_index])\n",
    "    train_lr_batches(lr_train[start_index:end_index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    fake_labels = np.zeroes((batch_size, 1))\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    \n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    \n",
    "    for batch in tqdm(range(len(train_hr_batches))):\n",
    "        lr_images = train_lr_batches[batch]\n",
    "        hr_images = train_hr_batches[batch]\n",
    "        \n",
    "        fake_images = generator.predict_on_batch(lr_images)\n",
    "        \n",
    "        discriminator.trainable = True\n",
    "        d_loss_gen = discriminator.train_on_batches(fake_images, fake_labels)\n",
    "        d_loss_real = discriminator.train_on_bataches(hr_images, real_labels)\n",
    "        \n",
    "        discriminator.trainbale = False\n",
    "        \n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
    "        \n",
    "        image_features = vgg.predict(hr_images)\n",
    "        \n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_images, hr_images], [real_labels, image_features])\n",
    "        \n",
    "        dis_losses.append(d_loss)\n",
    "        gen_losses.append(g_loss)\n",
    "\n",
    "gen_losses = np.array(gen_losses)\n",
    "dis_losses = np.array(dis_losses)\n",
    "\n",
    "avg_g_loss = np.sum(gen_losses, axis= 0)/ len(gen_losses)\n",
    "avg_d_loss = np.sum(dis_losses, axis= 0)/ len(dis_losses)\n",
    "\n",
    "print(\"epoch: \", e+1, \"gen_loss: \", avg_g_loss, \"dis_loss: \", avg_d_loss)\n",
    "\n",
    "if (e + 1) % 5 == 0:\n",
    "    generator.save(\"gen_e_\"+ str(e+1) + \".h5\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.load_model('gen_e_10.h5', compile= False)\n",
    "\n",
    "[X1, X2] = [lr_test, hr_test]\n",
    "\n",
    "ix = random.randint(0, len(X1), 1)\n",
    "src_image, tar_image = X1[ix], X2[ix]\n",
    "\n",
    "gen_image = generator.predict(src_image)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplots(231)\n",
    "plt.title(\"LR Image\")\n",
    "plt.imshow(src_image[0, :, :, :])\n",
    "plt.subplots(232)\n",
    "plt.title(\"SR\")\n",
    "plt.imshow(gen_image[0, :, :, :])\n",
    "plt.subplot(233)\n",
    "plt.title(\"HR Images\")\n",
    "plt.imshow(tar_image[0, :, :, :])\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
